{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Rapport : Estimation du Tarif des Concurrents :\n",
    "\n",
    "Dans le domaine de l’assurance, estimer avec précision les primes commerciales est un défi majeur en raison de la diversité et de la complexité des variables influençant leur calcul. Ces variables incluent des facteurs socio-démographiques (âge, sexe, statut matrimonial), des caractéristiques techniques des véhicules (puissance, type de carburant, âge), et des comportements des assurés (bonus/malus, usage du véhicule). La difficulté réside dans la modélisation efficace de ces variables hétérogènes et leur interaction pour prédire un montant juste, compétitif et adapté aux risques tout en s’adaptant aux évolutions du marché et des comportements des clients.\n",
    "\n",
    "Le but construire un modèle prédictif pour estimer la prime commerciale des concurrents à partir des données fournies."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Importation des Bibliothèques \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from typing import Dict, List, Any, Tuple\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.preprocessing import PolynomialFeatures, OneHotEncoder \n",
    "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor\n",
    "from sklearn.linear_model import LinearRegression, Ridge, Lasso, ElasticNet\n",
    "from lightgbm import LGBMRegressor\n",
    "from xgboost import XGBRegressor\n",
    "from catboost import CatBoostRegressor\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "from sklearn.metrics import r2_score, mean_absolute_error, mean_squared_error\n",
    "from sklearn.model_selection import learning_curve\n",
    "from common_function import(\n",
    "          load_config ,\n",
    "          load_data,\n",
    "          detect_missing_values ,\n",
    "          save_model_with_directory,\n",
    "          plot_box_plot,\n",
    "          plot_feature_distribution,\n",
    "          plot_correlation_matrix,\n",
    "          plot_scatter,\n",
    "          detect_outliers_summary,\n",
    "          cap_outliers,\n",
    "          log_transform,\n",
    "          scale_features,\n",
    "          preprocess_modeling,\n",
    "          evaluation_metrics,\n",
    "          evaluate_on_validation_set,\n",
    "          \n",
    ")\n",
    "import joblib\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Étape 1 : Préparation des données"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Charger et comprendre les données brutes afin de déterminer la qualité des données et les caractéristiques de chaque variable"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.Chargement de la Configuration et des Données"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" Charger le fichier de configuration pour accéder aux chemins d'accès et aux paramètres, \n",
    "puis  l'utiliser pour charger les données d'entraînement\n",
    "\"\"\"\n",
    "config = load_config(\"config\\config.yaml\") \n",
    "data=load_data(config['data']['train_path'])\n",
    "test_data=load_data(config['data']['test_path'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Les données comportent des **variables numériques** (***AgeConducteur***, ***BonusMalus***, ***AgeVehicule***, ***PrimeCommerciale***) et **des variables catégorielles** (SexeConducteur, FrequencePaiement, ClasseVehicule, etc.).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***PolicyId*** est un identifiant unique en format texte et ne sera pas utilisée pour l’entraînement.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Exploration et Nettoyage des donnés"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Identifier et gérer les valeurs manquantes, les incohérences et les outliers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.head(10) # Afficher les 10 premières lignes du dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "detect_missing_values(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**StatutMatrimonial** et **CodeProfession** ont un nombre important de valeurs manquantes, avec seulement 7372 valeurs renseignées sur 22481. \n",
    "La gestion des valeurs manquantes sera donc cruciale ici pour ne pas biaiser le modèle."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**NB**: il est préférable d'imputer les valeurs manquantes plutôt que de supprimer ces lignes, car cela entraînerait une perte d'environ 67% des données."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"les valeurs de StatutMatrimonial:\",data['StatutMatrimonial'].unique())\n",
    "print(\"les valeurs de CodeProfession :\",data['CodeProfession'].unique())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Options de gestion** :\n",
    "* **Imputation par le mode** : Remplir les valeurs manquantes avec la valeur la plus courante, si l’une des catégories est très représentée.\n",
    "* **Catégorie \"Non spécifé\"** : cette option permettrait de prendre en compte l'absence de cette information est significative, ce qui pourrait être pertinent.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**NB** : certains clients ne souhaitent pas déclarer leur statut\n",
    "\n",
    "Donc Je vais remplir les valeurs manquantes par la valeur \"Non spécifé\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_data(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Pré-traite les données en remplissant les valeurs manquantes pour certaines colonnes spécifiques.\n",
    "\n",
    "    Args:\n",
    "        df (pd.DataFrame): Le DataFrame contenant les données à pré-traiter.\n",
    "\n",
    "    Returns:\n",
    "        pd.DataFrame: Le DataFrame avec les valeurs manquantes remplies pour les colonnes 'StatutMatrimonial' et 'CodeProfession'.\n",
    "\n",
    "    Étapes de pré-traitement :\n",
    "        - Remplit les valeurs manquantes dans las colonne 'StatutMatrimonial'et 'CodeProfession' avec \"Non spécifé\".\n",
    "    \"\"\"\n",
    "    \n",
    "    df['StatutMatrimonial'].fillna(\"Non spécifié\", inplace=True)\n",
    "    df['CodeProfession'].fillna(\"Non spécifié\", inplace=True)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocess_data=preprocess_data(data) # Data with new vlaues\n",
    "preprocess_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Analyse exploratoire des données (EDA)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Obtenir une vue d’ensemble des statistiques de base pour chaque variable afin de déceler des patterns ou des anomalies dans les données.\n",
    "\n",
    "Identifier les variables les plus influentes sur PrimeCommerciale et de visualiser les relations entre les variables ."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* **3.1 Analyse statistique descriptive**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "**AgeConducteur**\n",
    "\n",
    "* **Moyenne**: 39.7 ans, avec un écart-type de 11.85 ans.\n",
    "* **Distribution**  : L’âge des conducteurs varie de 18 à 87 ans. Les percentiles indiquent que 50 % des conducteurs ont moins de 37 ans, et 75 % ont moins de 47 ans.\n",
    "\n",
    "* **Analyse** : La majorité des conducteurs sont dans un intervalle d'âge moyenne, ce qui est cohérent avec la démographie de nombreux assurés mais Les valeurs extrêmes, comme 87 ans, pourraient influencer la prime .\n",
    "\n",
    "**BonusMalus**\n",
    "\n",
    "* **Moyenne** : 63.24, avec un écart-type de 15.38.\n",
    "\n",
    "* **Distribution** : La valeur minimale de BonusMalus est de 50, indiquant des conducteurs sans accidents récents. La valeur maximale de 156 peut correspondre à des conducteurs avec un historique de sinistres.\n",
    "\n",
    "* **Analyse** : Cette variable a une signification directe sur le calcul de la prime. Un BonusMalus plus élevé peut être synonyme de primes plus coûteuses. La distribution montre que 75 % des assurés ont un BonusMalus inférieur à 72, ce qui suggère que la majorité des conducteurs ont un bon historique.\n",
    "\n",
    "\n",
    "\n",
    "**AgeVehicule (Âge du véhicule)**\n",
    "\n",
    "* **Moyenne** : 7.5 ans, avec un écart-type de 4.84 ans.\n",
    "* **Distribution** : L’âge du véhicule varie de 0 (véhicules neufs) à 89 ans. Les quartiles indiquent que 50 % des véhicules ont moins de 7 ans, et 75 % moins de 10 ans.\n",
    "\n",
    "* **Analyse** : La distribution est relativement concentrée autour de la moyenne, mais quelques véhicules très anciens peuvent nécessiter une attention particulière dans l'analyse, car ils pourraient influencer le modèle.\n",
    "\n",
    "\n",
    "\n",
    "**PrimeCommerciale (Variable cible)**\n",
    "\n",
    "* **Moyenne** : 420.79 , avec un écart-type de 219.26 \n",
    "* **Distribution** : Les primes vont de 91  à 2902.3 . La médiane est de 375.1 €, ce qui signifie que la moitié des assurés paient moins de cette valeur.\n",
    "\n",
    "* **Analyse** : La large gamme de primes reflète des variations importantes en fonction des caractéristiques des conducteurs et des véhicules. La queue de distribution des primes élevée (jusqu'à 2902 €) indique quelques valeurs extrêmes qui pourraient affecter la performance du modèle si elles sont mal gérées.\n",
    "\n",
    "\n",
    "\n",
    "***Conclusion et Implications***\n",
    "\n",
    "* **Normalisation** : Les variables AgeConducteur, BonusMalus, et AgeVehicule présentent des échelles différentes, il est donc pertinent de normaliser ou standardiser ces variables pour garantir une meilleure convergence des modèles linéaires.\n",
    "\n",
    "* **Outliers** : Les valeurs extrêmes de AgeVehicule et PrimeCommerciale nécessiteront une attention particulière. \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* **2.2 Visualisation des distributions et relations**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Numerical_colomuns=config['features']['numerical']\n",
    "Categorical_columns=config['features']['categorical']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(16, 8))\n",
    "sns.color_palette(\"coolwarm\")\n",
    "for i, col in enumerate(Numerical_colomuns, 1):\n",
    "          plt.subplot(2, 2, i)\n",
    "          plt.grid(True)       \n",
    "          plot_feature_distribution(preprocess_data,col)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**AgeConducteur** : La distribution de l’âge des conducteurs est légèrement asymétrique\n",
    "\n",
    "**BonusMalus** : La distribution de BonusMalus est très asymétrique, \n",
    "\n",
    "**AgeVehicule** : La majorité des véhicules ont un âge inférieur à 10 ans . Les véhicules plus anciens sont rares, mais ils pourraient entraîner des primes plus élevées en raison d'un risque accru lié à l’usure.\n",
    "\n",
    "**PrimeCommerciale** : La distribution de PrimeCommerciale  est fortement asymétrique, avec une majorité des primes situées entre 100 et 700 €. Il y a quelques valeurs élevées (au-delà de 2000 €), qui représentent des outliers potentiels. Cette distribution montre que la majorité des primes sont faibles, avec quelques valeurs extrêmes qui nécessiteront une attention particulière."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(14,12))\n",
    "sns.color_palette(\"dark\")\n",
    "target='PrimeCommerciale'\n",
    "for i, col in enumerate(Numerical_colomuns[:-1],1):\n",
    "          plt.subplot(3,1,i)\n",
    "          plot_scatter(preprocess_data,col,target)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**PrimeCommerciale VS AgeConducteur** :\n",
    "\n",
    "* La ligne de tendance montre que PrimeCommerciale diminue légèrement avec l'augmentation de l'âge du conducteur.\n",
    "\n",
    "\n",
    "* AgeConducteur dans le modèle est pertinent pour capter la variation de la prime selon les catégories d'âge.\n",
    "\n",
    "**PrimeCommerciale vs BonusMalus** :\n",
    "\n",
    "* Le graphique montre une tendance positive, où une augmentation du BonusMalus entraîne une hausse de la prime. \n",
    "\n",
    "* Cette relation renforce le choix d’inclure BonusMalus comme variable prédictive clé, car elle influence directement les ajustements de prime.\n",
    "\n",
    "\n",
    "**PrimeCommerciale vs AgeVehicule** :\n",
    "\n",
    "* Le graphique de dispersion montre que les primes diminuent avec l'âge du véhicule, illustrant la relation inverse entre la valeur du véhicule et son âge.\n",
    "\n",
    "* AgeVehicule doit être conservé dans le modèle, car il permet de prendre en compte le risque financier pour l'assureur en fonction de l'âge et de la valeur du véhicule."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,6))\n",
    "df_corr= preprocess_data[Numerical_colomuns]\n",
    "plot_correlation_matrix(df_corr)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* La corrélation modérée de 0.38 entre BonusMalus et PrimeCommerciale montre que plus le BonusMalus est élevé, plus la prime d'assurance (PrimeCommerciale) augmente. \n",
    "\n",
    "\n",
    "* Une corrélation de -0.46 est observée entre AgeVehicule et PrimeCommerciale. Cette relation négative suggère que les véhicules plus anciens ont des primes d’assurance plus faibles\n",
    "\n",
    "* La corrélation de -0.17 entre AgeConducteur et PrimeCommerciale est relativement faible, mais elle montre une légère tendance de réduction de la prime avec l'âge. Les conducteurs plus jeunes paient souvent des primes plus élevées, car ils sont considérés comme plus risqués.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Conslusion**\n",
    "\n",
    "* Les corrélations et les graphiques de dispersion démontre une compréhension claire des relations entre les variables et PrimeCommerciale. Les analyses montrent comment chaque variable influence la prime, ce qui est essentiel pour une modélisation efficace.\n",
    "\n",
    "* En sélectionnant BonusMalus, AgeVehicule, et AgeConducteur, nous capturons les facteurs de risque liés au comportement du conducteur, à la valeur du véhicule et à l’expérience du conducteur. Ces choix sont en cohérence avec les pratiques d’assurance et les standards de l’industrie.\n",
    "\n",
    "* Ces variables devraient contribuer de manière significative à la précision du modèle, car elles couvrent différents aspects du risque (comportement, valeur du véhicule, et profil d'âge). L’inclusion de ces variables est donc prévue pour optimiser la performance prédictive de PrimeCommerciale."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(16, 20))\n",
    "for i, column in enumerate(Categorical_columns, 1):\n",
    "    plt.subplot(5, 2, i)\n",
    "    sns.countplot(data=data, x=column, palette=\"viridis\")\n",
    "    plt.title(f\"Distribution of {column}\")\n",
    "    plt.xticks(rotation=45, ha='right')\n",
    "    plt.tight_layout()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Encodage One-Hot** et **Traitement des Valeurs \"Non spécifié\"** : L'encodage one-hot des catégories dominantes permet de minimiser le biais dans le modèle, et le traitement des valeurs \"Non spécifié\" comme catégorie .\n",
    "\n",
    "En intégrant des termes d’interaction entre des variables, on capture des relations complexes qui peuvent mieux expliquer la variabilité des primes.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(15, 20))\n",
    "# Plotting box plots for each continuous variable to visualize outliers\n",
    "for i, col in enumerate(Categorical_columns, 1):\n",
    "    plt.subplot(len(Categorical_columns)//2, 2, i)\n",
    "    plot_box_plot(preprocess_data ,col,'PrimeCommerciale')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Les graphiques montrent que les primes d’assurance sont influencées par plusieurs facteurs. Les femmes, les veufs/divorcés, et les professions comme agriculteur ou commerçant paient généralement des primes plus élevées. Les véhicules plus puissants, chers, ou utilisés à des fins professionnelles, ainsi que ceux garés dans la rue ou situés dans certaines régions, augmentent également le coût. Les paiements mensuels sont les plus onéreux. Ces variables clés sont essentielles pour affiner la prédiction des primes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Détection des Outliers\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "identifier les valeurs extrêmes qui peuvent fausser les résultats de la modélisation prédictive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(16, 8))\n",
    "\n",
    "for i, col in enumerate(Numerical_colomuns, 1):\n",
    "    plt.subplot(2, 2, i)\n",
    "    sns.boxplot(x=preprocess_data[col])\n",
    "    plt.title(f'Box Plot of {col}')\n",
    "    plt.grid(True)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En appliquant les méthodes de détection d’outliers sur les colonnes numériques, voici le nombre d'outliers détectés pour chaque variable "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "detect_outliers_summary(preprocess_data,Numerical_colomuns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Les box-plots et les résultats de détection des outliers montrent un nombre significatif de valeurs aberrantes dans les différentes variables, en particulier pour la variable cible PrimeCommerciale. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "**Actions**  :\n",
    "\n",
    "* **Capping des valeurs extrêmes** : Limiter les valeurs extrêmes à des seuils raisonnables pour PrimeCommerciale, BonusMalus, et AgeVehicule afin de réduire leur impact disproportionné sur le modèle.\n",
    "\n",
    "* **Transformation Logarithmique** : Appliquer une transformation logarithmique à pour stabiliser l’effet des valeurs extrêmes tout en préservant les relations d'ordre."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data=preprocess_data.copy()\n",
    "columns_do_capping = config['features']['capping']\n",
    "#scaled_columns = config['features']['scaled']\n",
    "for col in columns_do_capping:\n",
    "    train_data = cap_outliers(train_data, col) #Limite les valeurs extrêmes pour stabiliser les distributions.\n",
    "train_data=log_transform(train_data,Numerical_colomuns) #Limite les valeurs extrêmes pour stabiliser les distributions\n",
    "#train_data=scale_features(train_data,scaled_columns)\n",
    "train_data.drop(columns=Numerical_colomuns, inplace=True) #Garde uniquement les versions transformées des colonnes.\n",
    "print(train_data.info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(16, 8))\n",
    "\n",
    "# Plotting box plots for each continuous variable to visualize outliers\n",
    "for i, col in enumerate(scaled_columns, 1):\n",
    "    plt.subplot(2, 2, i)\n",
    "    sns.boxplot(x=train_data[col])\n",
    "    plt.title(f'Box Plot of {col}')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "L'application du capping et de la transformation logarithmique a permis de :\n",
    "\n",
    "Réduire l'impact des valeurs extrêmes dans chaque variable, en rendant les distributions plus symétriques et plus homogènes.\n",
    "Améliorer la stabilité des variables pour la modélisation, en s’assurant que les valeurs aberrantes n’influencent pas de manière disproportionnée les prédictions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.Feature-engineering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* On commence par créer une interaction entre l’âge du conducteur et l’âge du véhicule, ce qui permet d’explorer l’effet combiné de ces deux variables.\n",
    "* Ensuite, on simplifie l’analyse de l’âge du conducteur en le classant dans trois groupes : jeunes, matures et seniors.\n",
    "* Une autre idée est d’ajouter une caractéristique qui mesure la différence entre le bonus-malus et l’âge du conducteur, pour détecter des tendances intéressantes.\n",
    "* Pour exploiter les catégories d’âge, on les encode en valeurs numériques via un one-hot encoding.\n",
    "* Enfin, on génère des variables polynomiales pour capturer des relations non linéaires entre certaines colonnes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_interaction_feature(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Ajoute une caractéristique d'interaction entre l'âge du conducteur et l'âge du véhicule.\n",
    "    \"\"\"\n",
    "    df['Driver_Vehicle_Age_Interaction'] = df['AgeConducteur_log'] * df['AgeVehicule_log']\n",
    "    return df\n",
    "\n",
    "def bin_age_conducteur(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Effectue un binning de 'AgeConducteur_log' en trois catégories : 'Young', 'Mature' et 'Senior'.\n",
    "    \"\"\"\n",
    "    df['AgeConducteur_Binned'] = pd.cut(\n",
    "        df['AgeConducteur_log'],\n",
    "        bins=[-np.inf, np.log1p(25), np.log1p(50), np.inf],\n",
    "        labels=['Young', 'Mature', 'Senior']\n",
    "    )\n",
    "    return df\n",
    "\n",
    "def create_bonus_age_difference(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Crée une nouvelle caractéristique en soustrayant l'âge du conducteur du BonusMalus.\n",
    "    \"\"\"\n",
    "    df['Bonus_Age_Difference'] = df['BonusMalus_log'] - df['AgeConducteur_log']\n",
    "    return df\n",
    "\n",
    "def encode_binned_age(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Encode la colonne 'AgeConducteur_Binned' en variables fictives (one-hot encoding).\n",
    "    \"\"\"\n",
    "    encoder = OneHotEncoder(drop='first', sparse_output=False)\n",
    "    encoded_columns = encoder.fit_transform(df[['AgeConducteur_Binned']])\n",
    "    encoded_df = pd.DataFrame(encoded_columns, columns=encoder.get_feature_names_out(['AgeConducteur_Binned']))\n",
    "    df = pd.concat([df, encoded_df], axis=1)\n",
    "    df.drop(columns=['AgeConducteur_Binned'], inplace=True)\n",
    "    return df\n",
    "\n",
    "def add_polynomial_features(df: pd.DataFrame, columns: list, degree: int = 2) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Génère des caractéristiques polynomiales pour les colonnes spécifiées.\n",
    "    \"\"\"\n",
    "    poly = PolynomialFeatures(degree=degree, include_bias=False)\n",
    "    poly_features = poly.fit_transform(df[columns])\n",
    "    poly_feature_names = poly.get_feature_names_out(columns)\n",
    "    poly_df = pd.DataFrame(poly_features, columns=poly_feature_names)\n",
    "    df = pd.concat([df, poly_df], axis=1)\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Appliquer\n",
    "train_data = add_interaction_feature(train_data)\n",
    "train_data = bin_age_conducteur(train_data)\n",
    "train_data = create_bonus_age_difference(train_data)\n",
    "train_data = encode_binned_age(train_data)\n",
    "#train_data = add_polynomial_features(train_data, ['AgeConducteur_log', 'BonusMalus_log']) # j'ai pas utilisé les ploy model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data.to_csv(config['data']['train_cleaned_path'], index=False) # save data cleaned into a csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Feature-engineered Data:\")\n",
    "print(train_data.info())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ## 6.Séparation des Données et Encodage Variables Catégorielle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Prépare les données pour la modélisation en appliquant l'encodage One-Hot avec OneHotEncoder aux variables catégorielles,\n",
    "\n",
    "en supprimant les colonnes inutiles et en séparant les caractéristiques de la cible."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X,y=preprocess_modeling(train_data, target_column='PrimeCommerciale_log', drop_columns=['PolicyId'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Étape 2 : Préparation, Entraînement, Evaluation et validation du modèle de régression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.Séparation des Données d'Entraînement et de Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Sélection de modèles et stratégie d'évaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* ### 2.1 Linear Models : \n",
    "   Modèles linéaires avec ou sans régularisation, adaptés pour des relations linéaires entre variables.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "models_ln=config['models']['linear_models']\n",
    "cv = config['evaluation']['cv_folds']\n",
    "scoring_metric=config['evaluation']['scoring_metric']\n",
    "scoring=scoring_metric\n",
    "\n",
    "models_ln"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_classes = {\n",
    "    'LinearRegression': LinearRegression,\n",
    "    'RidgeRegression': Ridge,\n",
    "    'LassoRegression': Lasso,\n",
    "    'ElasticNetRegression': ElasticNet\n",
    "}\n",
    "\n",
    "# Define model parameters from your configuration\n",
    "\n",
    "# Dictionary to store initialized models\n",
    "models = {}\n",
    "\n",
    "# Initialize models with parameters\n",
    "for model_name, parameters in models_ln.items():\n",
    "    model_class = model_classes.get(model_name)  # Retrieve model class\n",
    "    if model_class:\n",
    "        models[model_name] = model_class(**parameters)  # Initialize and store the model\n",
    "\n",
    "# Display initialized models for verification\n",
    "for name, model in models.items():\n",
    "    print(f\"{name}: {model}\")\n",
    "\n",
    "# Verify the models dictionary\n",
    "models\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "results = {\n",
    "    'Model': [],\n",
    "    'Mean MSE': [],\n",
    "    'Mean R2': [],\n",
    "    'Mean MAE':[]\n",
    "}\n",
    "\n",
    "for name, model in models.items():\n",
    "    scores = evaluation_metrics(model, X_train, y_train, cv=cv)\n",
    "    results['Model'].append(name)\n",
    "    results['Mean MSE'].append(scores['Mean MSE'])\n",
    "    results['Mean R2'].append(scores['Mean R2'])\n",
    "    results['Mean MAE'].append(scores['Mean MAE'])\n",
    "    \n",
    "\n",
    "\n",
    "results_df = pd.DataFrame(results)\n",
    "print(\"Évaluation des Modèles avec Validation Croisée\")\n",
    "print(results_df)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_sizes = np.linspace(0.1, 1.0, 10)\n",
    "plt.figure(figsize=(12, 8))\n",
    "\n",
    "for model_name, model in models.items():\n",
    "    # Calcul des courbes d'apprentissage\n",
    "    train_sizes, train_scores, test_scores = learning_curve(\n",
    "        model, X, y, cv=5, train_sizes=train_sizes, scoring=scoring, n_jobs=-1\n",
    "    )\n",
    "    \n",
    "    # Moyenne et écart-type des scores d'apprentissage et de validation\n",
    "    train_scores_mean = -train_scores.mean(axis=1)\n",
    "    train_scores_std = train_scores.std(axis=1)\n",
    "    test_scores_mean = -test_scores.mean(axis=1)\n",
    "    test_scores_std = test_scores.std(axis=1)\n",
    "\n",
    "    # Tracer la courbe d'apprentissage pour chaque modèle\n",
    "    plt.plot(train_sizes, train_scores_mean, 'o-', label=f'{model_name} - Entraînement')\n",
    "    plt.plot(train_sizes, test_scores_mean, 'o--', label=f'{model_name} - Validation')\n",
    "\n",
    "    # Afficher l'intervalle de confiance\n",
    "    plt.fill_between(train_sizes, train_scores_mean - train_scores_std,\n",
    "                     train_scores_mean + train_scores_std, alpha=0.2)\n",
    "    plt.fill_between(train_sizes, test_scores_mean - test_scores_std,\n",
    "                     test_scores_mean + test_scores_std, alpha=0.2)\n",
    "\n",
    "# Personnalisation du graphique\n",
    "plt.xlabel(\"Nombre d'exemples d'apprentissage\")\n",
    "plt.ylabel(\"Erreur Quadratique Moyenne (MSE)\")\n",
    "plt.title(\"Courbes d'Apprentissage des Modèles\")\n",
    "plt.legend(loc=\"best\")\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_sizes, train_scores, val_scores = learning_curve(\n",
    "  models['RidgeRegression']  , X, y, cv=cv, scoring='neg_mean_squared_error', train_sizes=np.linspace(0.1, 1.0, 10)\n",
    ")\n",
    "\n",
    "# Calcul de la moyenne et de l'écart-type des erreurs d'entraînement et de validation\n",
    "train_errors_mean = -train_scores.mean(axis=1)\n",
    "train_errors_std = train_scores.std(axis=1)\n",
    "val_errors_mean = -val_scores.mean(axis=1)\n",
    "val_errors_std = val_scores.std(axis=1)\n",
    "\n",
    "# Tracé des courbes d'apprentissage\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(train_sizes, train_errors_mean, label=\"Erreur d'entraînement\", color=\"blue\")\n",
    "plt.fill_between(train_sizes, train_errors_mean - train_errors_std, train_errors_mean + train_errors_std, alpha=0.1, color=\"blue\")\n",
    "plt.plot(train_sizes, val_errors_mean, label=\"Erreur de validation\", color=\"red\")\n",
    "plt.fill_between(train_sizes, val_errors_mean - val_errors_std, val_errors_mean + val_errors_std, alpha=0.1, color=\"red\")\n",
    "\n",
    "# Ajout des labels et légendes\n",
    "plt.xlabel(\"Taille de l'ensemble d'entraînement\")\n",
    "plt.ylabel(\"Erreur Quadratique Moyenne (MSE)\")\n",
    "plt.title(\"Courbes d'apprentissage avec validation croisée\")\n",
    "plt.legend(loc=\"best\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* ### 2.2 Méthodes d'ensemble"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X,y=preprocess_modeling(train_data, target_column='PrimeCommerciale_log', drop_columns=['PolicyId','AgeConducteur_log','BonusMalus_log'])\n",
    "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "X_train.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "models_en=config[\"models\"][\"ensemble_methods\"]\n",
    "models_en"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "models = {}\n",
    "\n",
    "# Model classes mapping\n",
    "model_classes = {\n",
    "    \"RandomForest\": RandomForestRegressor,\n",
    "    \"GradientBoosting\": GradientBoostingRegressor,\n",
    "    \"XGBoost\": XGBRegressor,\n",
    "}\n",
    "\n",
    "# Initialize models using the configuration\n",
    "for model_name, parameters in models_en.items():\n",
    "    model_class = model_classes.get(model_name)  # Retrieve model class\n",
    "    if model_class:\n",
    "        try:\n",
    "            models[model_name] = model_class(**parameters)  # Initialize and store the model\n",
    "        except Exception as e:\n",
    "            print(f\"Error initializing {model_name}: {e}\")\n",
    "\n",
    "# Display initialized models for verification\n",
    "for name, model in models.items():\n",
    "    print(f\"{name}: {model}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = {\n",
    "    'Model': [],\n",
    "    'Mean MSE': [],\n",
    "    'Mean R2': [],\n",
    "    'Mean MAE':[]\n",
    "}\n",
    "\n",
    "for name, model in models.items():\n",
    "    scores = evaluation_metrics(model, X_train, y_train, cv=cv)\n",
    "    results['Model'].append(name)\n",
    "    results['Mean MSE'].append(scores['Mean MSE'])\n",
    "    results['Mean R2'].append(scores['Mean R2'])\n",
    "    results['Mean MAE'].append(scores['Mean MAE'])\n",
    "    \n",
    "\n",
    "\n",
    "results_df = pd.DataFrame(results)\n",
    "print(\"Évaluation des Modèles avec Validation Croisée\")\n",
    "print(results_df)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_sizes = np.linspace(0.1, 1.0, 10)\n",
    "plt.figure(figsize=(12, 8))\n",
    "\n",
    "for model_name, model in models.items():\n",
    "    # Calcul des courbes d'apprentissage\n",
    "    train_sizes, train_scores, test_scores = learning_curve(\n",
    "        model, X, y, cv=5, train_sizes=train_sizes, scoring=scoring, n_jobs=-1\n",
    "    )\n",
    "    \n",
    "    # Moyenne et écart-type des scores d'apprentissage et de validation\n",
    "    train_scores_mean = -train_scores.mean(axis=1)\n",
    "    train_scores_std = train_scores.std(axis=1)\n",
    "    test_scores_mean = -test_scores.mean(axis=1)\n",
    "    test_scores_std = test_scores.std(axis=1)\n",
    "\n",
    "    # Tracer la courbe d'apprentissage pour chaque modèle\n",
    "    plt.plot(train_sizes, train_scores_mean, 'o-', label=f'{model_name} - Entraînement')\n",
    "    plt.plot(train_sizes, test_scores_mean, 'o--', label=f'{model_name} - Validation')\n",
    "\n",
    "    # Afficher l'intervalle de confiance\n",
    "    plt.fill_between(train_sizes, train_scores_mean - train_scores_std,\n",
    "                     train_scores_mean + train_scores_std, alpha=0.1)\n",
    "    plt.fill_between(train_sizes, test_scores_mean - test_scores_std,\n",
    "                     test_scores_mean + test_scores_std, alpha=0.1)\n",
    "\n",
    "# Personnalisation du graphique\n",
    "plt.xlabel(\"Nombre d'exemples d'apprentissage\")\n",
    "plt.ylabel(\"Erreur Quadratique Moyenne (MSE)\")\n",
    "plt.title(\"Courbes d'Apprentissage des Modèles\")\n",
    "plt.legend(loc=\"best\")\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_sizes, train_scores, val_scores = learning_curve(\n",
    "models['RandomForest']  , X, y, cv=cv, scoring='neg_mean_squared_error', train_sizes=np.linspace(0.1, 1.0, 10)\n",
    ")\n",
    "# Calcul de la moyenne et de l'écart-type des erreurs d'entraînement et de validation\n",
    "train_errors_mean = -train_scores.mean(axis=1)\n",
    "train_errors_std = train_scores.std(axis=1)\n",
    "val_errors_mean = -val_scores.mean(axis=1)\n",
    "val_errors_std = val_scores.std(axis=1)\n",
    "\n",
    "# Tracé des courbes d'apprentissage\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(train_sizes, train_errors_mean, label=\"Erreur d'entraînement\", color=\"blue\")\n",
    "plt.fill_between(train_sizes, train_errors_mean - train_errors_std, train_errors_mean + train_errors_std, alpha=0.1, color=\"blue\")\n",
    "plt.plot(train_sizes, val_errors_mean, label=\"Erreur de validation\", color=\"red\")\n",
    "plt.fill_between(train_sizes, val_errors_mean - val_errors_std, val_errors_mean + val_errors_std, alpha=0.1, color=\"red\")\n",
    "\n",
    "# Ajout des labels et légendes\n",
    "plt.xlabel(\"Taille de l'ensemble d'entraînement\")\n",
    "plt.ylabel(\"Erreur Quadratique Moyenne (MSE)\")\n",
    "plt.title(\"Courbes d'apprentissage avec validation croisée\")\n",
    "plt.legend(loc=\"best\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_sizes, train_scores, val_scores = learning_curve(\n",
    "models['XGBoost']  , X, y, cv=cv, scoring='neg_mean_squared_error', train_sizes=np.linspace(0.1, 1.0, 10)\n",
    ")\n",
    "# Calcul de la moyenne et de l'écart-type des erreurs d'entraînement et de validation\n",
    "train_errors_mean = -train_scores.mean(axis=1)\n",
    "train_errors_std = train_scores.std(axis=1)\n",
    "val_errors_mean = -val_scores.mean(axis=1)\n",
    "val_errors_std = val_scores.std(axis=1)\n",
    "\n",
    "# Tracé des courbes d'apprentissage\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(train_sizes, train_errors_mean, label=\"Erreur d'entraînement\", color=\"blue\")\n",
    "plt.fill_between(train_sizes, train_errors_mean - train_errors_std, train_errors_mean + train_errors_std, alpha=0.1, color=\"blue\")\n",
    "plt.plot(train_sizes, val_errors_mean, label=\"Erreur de validation\", color=\"red\")\n",
    "plt.fill_between(train_sizes, val_errors_mean - val_errors_std, val_errors_mean + val_errors_std, alpha=0.1, color=\"red\")\n",
    "\n",
    "# Ajout des labels et légendes\n",
    "plt.xlabel(\"Taille de l'ensemble d'entraînement\")\n",
    "plt.ylabel(\"Erreur Quadratique Moyenne (MSE)\")\n",
    "plt.title(\"Courbes d'apprentissage avec validation croisée\")\n",
    "plt.legend(loc=\"best\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* ### 2.3 NeuralNetwork MLP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Mlp_model=config['models']['neural_networks']\n",
    "Mlp_model['MLP']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Mlp_model['MLP']=MLPRegressor(**Mlp_model['MLP'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "results = {\n",
    "    'Model': [],\n",
    "    'Mean MSE': [],\n",
    "    'Mean R2': [],\n",
    "    'Mean MAE':[]\n",
    "}\n",
    "\n",
    "for name, model in Mlp_model.items():\n",
    "    scores = evaluation_metrics(model, X_train, y_train, cv=cv)\n",
    "    results['Model'].append(name)\n",
    "    results['Mean MSE'].append(scores['Mean MSE'])\n",
    "    results['Mean R2'].append(scores['Mean R2'])\n",
    "    results['Mean MAE'].append(scores['Mean MAE'])\n",
    "    \n",
    "\n",
    "\n",
    "results_df = pd.DataFrame(results)\n",
    "print(\"Évaluation des Modèles avec Validation Croisée\")\n",
    "print(results_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_sizes = np.linspace(0.1, 1.0, 10)\n",
    "plt.figure(figsize=(12, 8))\n",
    "\n",
    "    # Calcul des courbes d'apprentissage\n",
    "train_sizes, train_scores, test_scores = learning_curve(\n",
    "        model, X, y, cv=5, train_sizes=train_sizes, scoring=scoring, n_jobs=-1\n",
    "    )\n",
    "    \n",
    "    # Moyenne et écart-type des scores d'apprentissage et de validation\n",
    "train_scores_mean = -train_scores.mean(axis=1)\n",
    "train_scores_std = train_scores.std(axis=1)\n",
    "test_scores_mean = -test_scores.mean(axis=1)\n",
    "test_scores_std = test_scores.std(axis=1)\n",
    "\n",
    "    # Tracer la courbe d'apprentissage pour chaque modèle\n",
    "plt.plot(train_sizes, train_scores_mean, 'o-', label= 'Entraînement')\n",
    "plt.plot(train_sizes, test_scores_mean, 'o--', label=' Validation')\n",
    "\n",
    "    # Afficher l'intervalle de confiance\n",
    "plt.fill_between(train_sizes, train_scores_mean - train_scores_std,\n",
    "                     train_scores_mean + train_scores_std, alpha=0.1)\n",
    "plt.fill_between(train_sizes, test_scores_mean - test_scores_std,\n",
    "                     test_scores_mean + test_scores_std, alpha=0.1)\n",
    "\n",
    "# Personnalisation du graphique\n",
    "plt.xlabel(\"Nombre d'exemples d'apprentissage\")\n",
    "plt.ylabel(\"Erreur Quadratique Moyenne (MSE)\")\n",
    "plt.title(\"Courbes d'Apprentissage des Modèles\")\n",
    "plt.legend(loc=\"best\")\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Model=Mlp_model['MLP'].fit(X_train,y_train)\n",
    "y_pred=Model.predict(X_val)\n",
    "print('Validation on set :',evaluate_on_validation_set(Model,y_val,y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Après une comparaison des modèles, le modèle Mlpregressor a démontré une performance supérieure grâce à un ajustement optimisé des hyperparamètres et à l'application de techniques efficaces pour limiter le surapprentissage (overfitting).\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Anlayse des Résidus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy.stats as stats\n",
    "residuals = y_val - y_pred\n",
    "\n",
    "\n",
    "# 1. Histogramme des résidus\n",
    "plt.figure(figsize=(12, 8))\n",
    "plt.subplot(2, 2, 1)\n",
    "sns.histplot(residuals, kde=True, color=\"blue\")\n",
    "plt.title(\"Histogramme des Résidus\")\n",
    "plt.xlabel(\"Résidu\")\n",
    "plt.ylabel(\"Fréquence\")\n",
    "\n",
    "# 2. Graphique des résidus vs valeurs prédites\n",
    "plt.subplot(2, 2, 2)\n",
    "plt.scatter(y_pred, residuals, alpha=0.5, color=\"green\")\n",
    "plt.axhline(y=0, color='r', linestyle='--')\n",
    "plt.title(\"Résidus vs Valeurs Prédites\")\n",
    "plt.xlabel(\"Valeurs Prédites\")\n",
    "plt.ylabel(\"Résidu\")\n",
    "\n",
    "# 3. QQ-plot pour la normalité des résidus\n",
    "plt.subplot(2, 2, 3)\n",
    "stats.probplot(residuals, dist=\"norm\", plot=plt)\n",
    "plt.title(\"QQ-plot des Résidus\")\n",
    "\n",
    "# Afficher les graphiques\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Les résidus suivent une distribution normale, centrée autour de 0, indiquant que les erreurs sont bien réparties.\n",
    "\n",
    "* Pour les Résidus vs Valeurs Prédictes : Pas de structure évidente, confirmant une bonne homogénéité des erreurs. Cependant, une légère dispersion est visible pour des valeurs prédites élevées.\n",
    "\n",
    "* QQ-plot : Les résidus suivent globalement la ligne théorique, suggérant une normalité acceptable avec de légères déviations aux extrêmes.\n",
    "\n",
    "En conclusion, le modèle est bien ajusté, avec des erreurs raisonnablement réparties et peu de biais visibles."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Sauvegarde du Modèle avec Chemin Configuré"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_dir=config['data']['model_save_path']  \n",
    "save_model_with_directory(Model,model_dir,'Model.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Étape 3 :Exportation des prédictions :\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocess_data_test=preprocess_data(test_data) # Data with new vlaues\n",
    "preprocess_data_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# smae data preprocessing \n",
    "test_data_pre=preprocess_data_test.copy()\n",
    "columns_do_capping = config['features']['capping'][:-1]\n",
    "scaled_columns = config['features']['scaled'][:-1]\n",
    "for col in columns_do_capping:\n",
    "    test_data_pre = cap_outliers(test_data_pre, col) #Limite les valeurs extrêmes pour stabiliser les distributions.\n",
    "test_data_pre=log_transform(test_data_pre,Numerical_colomuns[:-1]) #Limite les valeurs extrêmes pour stabiliser les distributions\n",
    "#train_data=scale_features(train_data,scaled_columns)\n",
    "test_data_pre.drop(columns=Numerical_colomuns[:-1], inplace=True) #Garde uniquement les versions transformées des colonnes.\n",
    "print(test_data_pre.info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data_pre = add_interaction_feature(test_data_pre)\n",
    "test_data_pre = bin_age_conducteur(test_data_pre)\n",
    "test_data_pre = create_bonus_age_difference(test_data_pre)\n",
    "test_data_pre = encode_binned_age(test_data_pre)\n",
    "#test_data_pre = add_polynomial_features(test_data_pre, ['AgeConducteur_log', 'BonusMalus_log'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test=preprocess_modeling(test_data_pre,drop_columns=['PolicyId'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test['PuissanceVehicule_P6'] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "expected_features = list(Model.feature_names_in_)\n",
    "\n",
    "# Réorganiser les colonnes dans l’ordre attendu\n",
    "X_test = X_test[expected_features]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert list(X_test.columns) == list(expected_features), \"Les colonnes ne sont toujours pas alignées !\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_log=Model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "y_pred=np.exp(y_pred_log)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "config['data']['output_path']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Q1 = data['PrimeCommerciale'].quantile(0.25)\n",
    "Q3 = data['PrimeCommerciale'].quantile(0.75)\n",
    "IQR = Q3 - Q1\n",
    "lower_bound = Q1 - 1.5 * IQR\n",
    "upper_bound = Q3 + 1.5 * IQR\n",
    "bounds = {\"lower\": lower_bound, \"upper\": upper_bound}\n",
    "y_pred = np.where(y_pred < bounds[\"lower\"], bounds[\"lower\"], y_pred)\n",
    "y_pred = np.where(y_pred > bounds[\"upper\"], bounds[\"upper\"], y_pred) \n",
    "\n",
    "resultas=pd.DataFrame({\n",
    "          \"PolicyId\":test_data['PolicyId'],\n",
    "          \"PrimeCommercialePred\": y_pred\n",
    "})\n",
    "\n",
    "\n",
    "resultas.to_csv(config['data']['output_path'], index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Conclusion "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Résultats\n",
    "- Le modèle le plus performant a été sélectionné après optimisation des hyperparamètres.\n",
    "- Les métriques obtenues, comme le R² et l’erreur quadratique moyenne (RMSE), montrent une\n",
    " amélioration significative après nettoyage,l’ajout des nouvelles caractéristiques et l’optimisation.\n",
    " \n",
    "Livrables\n",
    " - Un fichier CSV contenant les prédictions (PolicyId et PrimeCommercialePred) sur le jeu de données test.\n",
    " - Un notebook documentant l’ensemble des étapes, des analyses exploratoires à l’entraînement du modèle.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
