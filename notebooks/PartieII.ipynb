{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Partie II : Étude de la dérive\n",
    "\n",
    "Les performances du modèle initial peuvent être affectées par des changements dans les données utilisées pour les prédictions, tels que des évolutions dans les distributions des variables explicatives (data drift) ou des modifications dans la relation entre ces variables et la cible (concept drift). La problématique est donc de comprendre et d’évaluer l’impact de ces dérives sur la précision du modèle, d'identifier les facteurs responsables de la dégradation des performances, et de proposer des ajustements ou des stratégies pour maintenir la pertinence du modèle dans\n",
    "\n",
    "un contexte évolutif et changeant. Cette analyse permettra d’assurer une prise de décision adaptée aux nouvelles caractéristiques des données tout en maintenant la fiabilité des prédictions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importation des Bibliothèques :\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from scipy import stats\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "from sklearn.preprocessing import PolynomialFeatures, OneHotEncoder \n",
    "from sklearn.linear_model import LinearRegression\n",
    "from typing import Dict, List, Any, Tuple\n",
    "from scipy.spatial.distance import jensenshannon\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from common_function import(\n",
    "          load_config ,\n",
    "          load_data,\n",
    "          load_model,\n",
    "          detect_missing_values ,\n",
    "          plot_box_plot,\n",
    "          plot_feature_distribution,\n",
    "          cap_outliers,\n",
    "          log_transform,\n",
    "          preprocess_modeling,\n",
    "          analyze_data_drift,\n",
    "          evaluation_metrics,\n",
    "          evaluate_on_validation_set, \n",
    "          calculate_jsd_categorical,\n",
    "          preprocess_columns,\n",
    "          div_jen_shanon,\n",
    "          comparer_matrices_correlation     \n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.Chargement de la Configuration et des Données"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = load_config(\"config\\config.yaml\") #\n",
    "data_drift=load_data(config['data']['drift_path'])\n",
    "data_train=load_data(config['data']['train_path'])\n",
    "data=data_drift\n",
    "Numerical_colomuns=config['features']['numerical']\n",
    "Categorical_columns=config['features']['categorical']\n",
    "Numerical_colomuns_log=config['features']['numerical_log']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(data.head())\n",
    "print(data.info())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Fonctions auxiliaires"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_data(df: pd.DataFrame) -> pd.DataFrame: \n",
    "    \"\"\"\n",
    "    Pré-traite les données en remplissant les valeurs manquantes pour certaines colonnes spécifiques.\n",
    "\n",
    "    Args:\n",
    "        df (pd.DataFrame): Le DataFrame contenant les données à pré-traiter.\n",
    "\n",
    "    Returns:\n",
    "        pd.DataFrame: Le DataFrame avec les valeurs manquantes remplies pour les colonnes 'StatutMatrimonial' et 'CodeProfession'.\n",
    "\n",
    "    Étapes de pré-traitement :\n",
    "        - Remplit les valeurs manquantes dans la colonne 'StatutMatrimonial' avec la modalité la plus fréquente.\n",
    "        - Remplit les valeurs manquantes dans la colonne 'CodeProfession' avec \"Non spécifié\".\n",
    "    \"\"\"\n",
    "    \n",
    "    df['StatutMatrimonial'].fillna(\"Non spécifié\", inplace=True)\n",
    "    df['CodeProfession'].fillna(\"Non spécifié\", inplace=True)\n",
    "    return df\n",
    "\n",
    "def add_interaction_feature(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Ajoute une caractéristique d'interaction entre l'âge du conducteur et l'âge du véhicule.\n",
    "    \"\"\"\n",
    "    df['Driver_Vehicle_Age_Interaction'] = df['AgeConducteur_log'] * df['AgeVehicule_log']\n",
    "    return df\n",
    "\n",
    "def bin_age_conducteur(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Effectue un binning de 'AgeConducteur_log' en trois catégories : 'Young', 'Mature' et 'Senior'.\n",
    "    \"\"\"\n",
    "    df['AgeConducteur_Binned'] = pd.cut(\n",
    "        df['AgeConducteur_log'],\n",
    "        bins=[-np.inf, np.log1p(25), np.log1p(50), np.inf],\n",
    "        labels=['Young', 'Mature', 'Senior']\n",
    "    )\n",
    "    return df\n",
    "\n",
    "def create_bonus_age_difference(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Crée une nouvelle caractéristique en soustrayant l'âge du conducteur du BonusMalus.\n",
    "    \"\"\"\n",
    "    df['Bonus_Age_Difference'] = df['BonusMalus_log'] - df['AgeConducteur_log']\n",
    "    return df\n",
    "\n",
    "def encode_binned_age(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Encode la colonne 'AgeConducteur_Binned' en variables fictives (one-hot encoding).\n",
    "    \"\"\"\n",
    "    encoder = OneHotEncoder(drop='first', sparse_output=False)\n",
    "    encoded_columns = encoder.fit_transform(df[['AgeConducteur_Binned']])\n",
    "    encoded_df = pd.DataFrame(encoded_columns, columns=encoder.get_feature_names_out(['AgeConducteur_Binned']))\n",
    "    df = pd.concat([df, encoded_df], axis=1)\n",
    "    df.drop(columns=['AgeConducteur_Binned'], inplace=True)\n",
    "    return df\n",
    "\n",
    "def add_polynomial_features(df: pd.DataFrame, columns: list, degree: int = 2) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Génère des caractéristiques polynomiales pour les colonnes spécifiées.\n",
    "    \"\"\"\n",
    "    poly = PolynomialFeatures(degree=degree, include_bias=False)\n",
    "    poly_features = poly.fit_transform(df[columns])\n",
    "    poly_feature_names = poly.get_feature_names_out(columns)\n",
    "    poly_df = pd.DataFrame(poly_features, columns=poly_feature_names)\n",
    "    df = pd.concat([df, poly_df], axis=1)\n",
    "    return df\n",
    "def tracer_distributions_categoriques(train_data :pd.DataFrame, new_data:pd.DataFrame, colonnes_categoriques:list)->None:\n",
    "    \"\"\"\n",
    "    Visualise les distributions des colonnes catégoriques entre deux ensembles de données en utilisant des sous-graphiques.\n",
    "\n",
    "    Paramètres :\n",
    "    - train_data : DataFrame pour l'ensemble d'entraînement.\n",
    "    - new_data : DataFrame pour l'ensemble de nouvelles données.\n",
    "    - colonnes_categoriques : Liste des colonnes catégoriques à comparer.\n",
    "    \"\"\"\n",
    "    # Calculer le nombre de lignes et de colonnes pour les sous-graphiques\n",
    "    nb_colonnes = len(colonnes_categoriques)\n",
    "    cols = 2  # Nombre de colonnes dans la grille de sous-graphiques\n",
    "    rows = (nb_colonnes + cols - 1) // cols  # Calcul du nombre de lignes nécessaires\n",
    "    \n",
    "    fig, axes = plt.subplots(rows, cols, figsize=(15, 5 * rows))\n",
    "    axes = axes.flatten()  # Aplatir les axes pour les parcourir facilement\n",
    "    \n",
    "    for i, colonne in enumerate(colonnes_categoriques):\n",
    "        # Fréquences des valeurs dans chaque ensemble\n",
    "        frequence_train = train_data[colonne].value_counts(normalize=True).sort_index()\n",
    "        frequence_new = new_data[colonne].value_counts(normalize=True).sort_index()\n",
    "        \n",
    "        # Combiner les deux distributions pour la comparaison\n",
    "        comparaison_df = pd.DataFrame({\n",
    "            \"Entraînement\": frequence_train,\n",
    "            \"Nouveau\": frequence_new\n",
    "        }).fillna(0)\n",
    "        \n",
    "        # Tracer le graphique en barres\n",
    "        comparaison_df.plot(kind=\"bar\", width=0.8, alpha=0.8, ax=axes[i])\n",
    "        axes[i].set_title(f\"Comparaison des distributions - {colonne}\")\n",
    "        axes[i].set_ylabel(\"Fréquence relative\")\n",
    "        axes[i].set_xlabel(\"Catégories\")\n",
    "        axes[i].legend(title=\"Ensemble de données\")\n",
    "        axes[i].grid(axis=\"y\", linestyle=\"--\", alpha=0.6)\n",
    "        axes[i].tick_params(axis=\"x\", rotation=45)\n",
    "    \n",
    "    # Désactiver les axes inutilisés\n",
    "    for j in range(len(colonnes_categoriques), len(axes)):\n",
    "        fig.delaxes(axes[j])\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.Prétraitement des données"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pre_data=preprocess_data(data).copy()\n",
    "pre_train=preprocess_data(data_train).copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Nettoyage des donnés"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_data=pre_data\n",
    "columns_do_capping = config['features']['capping']\n",
    "for col in columns_do_capping:\n",
    "    X_data = cap_outliers(X_data, col) #Limite les valeurs extrêmes pour stabiliser les distributions.\n",
    "\n",
    "X_data=log_transform(X_data,Numerical_colomuns) #Limite les valeurs extrêmes pour stabiliser les distributions.\n",
    "X_data.drop(columns=Numerical_colomuns, inplace=True) #Garde uniquement les versions transformées des colonnes.\n",
    "print(X_data.info())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Feature Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_data = add_interaction_feature(X_data)\n",
    "X_data = bin_age_conducteur(X_data)\n",
    "X_data = create_bonus_age_difference(X_data)\n",
    "X_data = encode_binned_age(X_data)\n",
    "#train_data = add_polynomial_features(train_data, ['AgeConducteur_log', 'BonusMalus_log'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Feature-engineered Data:\")\n",
    "print(X_data.info())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.Analyse des dérives des données"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Model=load_model(config['data']['model_path'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = preprocess_modeling(X_data, target_column='PrimeCommerciale_log', drop_columns=['PolicyId'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "expected_columns = list(Model.feature_names_in_)\n",
    "X=preprocess_columns(X,expected_columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert list(X.columns) == list(expected_columns), \"Les colonnes ne correspondent toujours pas !\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data_cleand=load_data(config['data']['train_cleaned_path'])\n",
    "X_train,y_train=preprocess_modeling(train_data_cleand, target_column='PrimeCommerciale_log', drop_columns=['PolicyId'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "expected_columns = list(Model.feature_names_in_)\n",
    "X_train = X_train[expected_columns]\n",
    "y_pred_train = Model.predict(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Evaluation sur les donnés Entrainment\")\n",
    "print(evaluate_on_validation_set(Model,y_train,y_pred_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_shift=Model.predict(X)\n",
    "print(\"Evaluation sur les donnés drift\")\n",
    "print(evaluate_on_validation_set(Model,y,y_pred_shift))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Les performances du modèle se sont fortement dégradées sur les données d’entraînement après le drift, comme en témoignent les métriques\n",
    "\n",
    "le drift a un impact majeur sur les performances du modèle.\n",
    "\n",
    "Un data drift dans les distributions des caractéristiques.\n",
    "la relation entre les caractéristiques et la cible a changé.(Un concept drift )\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "residuals_train = y_train - y_pred_train  # Résidus pour l'entraînement\n",
    "residuals_shift = y - y_pred_shift   # Résidus pour le test\n",
    "\n",
    "# Créer une figure\n",
    "plt.figure(figsize=(14, 10))\n",
    "\n",
    "# 1. Histogramme des résidus\n",
    "plt.subplot(2, 3, 1)\n",
    "sns.histplot(residuals_train, kde=True, color=\"blue\", label=\"Train\", alpha=0.6)\n",
    "sns.histplot(residuals_shift, kde=True, color=\"orange\", label=\"shift\", alpha=0.6)\n",
    "plt.title(\"Histogramme des Résidus (Train vs shfit)\")\n",
    "plt.xlabel(\"Résidu\")\n",
    "plt.ylabel(\"Fréquence\")\n",
    "plt.legend()\n",
    "\n",
    "# 2. Graphique des résidus vs valeurs prédites\n",
    "plt.subplot(2, 3, 2)\n",
    "plt.scatter(y_pred_train, residuals_train, alpha=0.5, color=\"blue\", label=\"Train\")\n",
    "plt.scatter(y_pred_shift, residuals_shift, alpha=0.5, color=\"orange\", label=\"drift\")\n",
    "plt.axhline(y=0, color='r', linestyle='--')\n",
    "plt.title(\"Résidus vs Valeurs Prédites\")\n",
    "plt.xlabel(\"Valeurs Prédites\")\n",
    "plt.ylabel(\"Résidu\")\n",
    "plt.legend()\n",
    "\n",
    "# 3. QQ-plot pour la normalité des résidus (Train)\n",
    "plt.subplot(2, 3, 3)\n",
    "stats.probplot(residuals_train, dist=\"norm\", plot=plt)\n",
    "plt.title(\"QQ-plot des Résidus (Train)\")\n",
    "\n",
    "# 4. QQ-plot pour la normalité des résidus ()\n",
    "plt.subplot(2, 3, 4)\n",
    "stats.probplot(residuals_shift, dist=\"norm\", plot=plt)\n",
    "plt.title(\"QQ-plot des Résidus (drift)\")\n",
    "\n",
    "# 5. Distribution comparative avec KDE\n",
    "plt.subplot(2, 3, 5)\n",
    "sns.kdeplot(residuals_train, color=\"blue\", label=\"Train\", fill=True, alpha=0.5)\n",
    "sns.kdeplot(residuals_shift, color=\"orange\", label=\"drift\", fill=True, alpha=0.5)\n",
    "plt.title(\"Comparaison des Densités des Résidus\")\n",
    "plt.xlabel(\"Résidu\")\n",
    "plt.ylabel(\"Densité\")\n",
    "plt.legend()\n",
    "\n",
    "# Afficher les graphiques\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analyse des Résidus et Interprétation\n",
    "\n",
    "## 1. Histogramme des Résidus (Train vs Drift)\n",
    "- **Train (bleu)** : Résidus centrés autour de 0, distribution étroite.  \n",
    "- **Drift (orange)** : Résidus déplacés vers des valeurs positives, distribution plus large.  \n",
    "- **Conclusion** : Les prédictions sur le drift sont biaisées et sous-estiment systématiquement les valeurs réelles.\n",
    "\n",
    "---\n",
    "\n",
    "## 2. Résidus vs Valeurs Prédites\n",
    "- **Train (bleu)** : Résidus uniformément répartis autour de 0.  \n",
    "- **Drift (orange)** : Résidus croissants avec les prédictions, signalant une erreur systématique.  \n",
    "- **Conclusion** : Le modèle ne généralise pas bien sur les données drift.\n",
    "\n",
    "---\n",
    "\n",
    "## 3. QQ-Plot des Résidus\n",
    "- **Train** : Résidus alignés avec la diagonale, suggérant une distribution normale.  \n",
    "- **Drift** : Déviation significative avec des valeurs extrêmes.  \n",
    "- **Conclusion** : Les données drift introduisent un comportement non normal, révélant une mauvaise adaptation.\n",
    "\n",
    "---\n",
    "\n",
    "## 4. Comparaison des Densités des Résidus\n",
    "- **Drift** : Résidus déplacés vers des valeurs positives avec une variance plus élevée.  \n",
    "- **Conclusion** : Une dérive globale dans les données provoque un biais systématique dans les prédictions.\n",
    "\n",
    "---\n",
    "\n",
    "## Résumé\n",
    "- Le modèle est sensible aux données drift, montrant des résidus biaisés et non uniformes.  \n",
    "- **Impact** : Dégradation des performances et perte de généralisation.  \n",
    "- **Action Recommandée** : Réentraîner le modèle sur des données récentes pour restaurer la robustesse.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analyse de la Dégradation des Performances et des Dérives ."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.data drift"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(16, 10))  # Setting up a large figure to hold all subplots\n",
    "\n",
    "for i, col in enumerate(Numerical_colomuns, 1):\n",
    "    plt.subplot(2, 2, i)  # Create a 2x2 grid of subplots\n",
    "    plot_feature_distribution(data_train, col)  # Plot for data_train\n",
    "    plot_feature_distribution(data_drift, col)  # Plot for data_drift\n",
    "    \n",
    "    # Add a legend to indicate which dataset each color represents\n",
    "    plt.legend(['data_train', 'data_drift'])\n",
    "\n",
    "plt.tight_layout()  # Adjust layout for better spacing between plots\n",
    "plt.show()\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**AgeConducteur** \n",
    "\n",
    "* Augmentation des jeunes conducteurs (20-30 ans) dans les donnés drift.-> Changement modéré, influence sur les prédictions\n",
    "\n",
    "**BonusMalus** \n",
    "\n",
    "* Forte augmentation des faibles valeurs dans data_drift.-> Dérive significative, risque élevé de mauvaise prédiction ((si le modèle est sensible à cette variable.))\n",
    "\n",
    "**AgeVehicule**\n",
    "\n",
    "* Augmentation des véhicules récents (0-20 ans), réduction des véhicules anciens. -> Dérive importante, reflète un changement notable dans les données.\n",
    "\n",
    "**PrimeCommerciale** :\n",
    "\n",
    "* Légères variations dans les plages, avec un glissement vers des valeurs plus élevéesChangement modéré, mais influence potentielle sur la prédiction des primes.\n",
    "\n",
    "\n",
    "\n",
    "* Dérive notable observée sur BonusMalus et AgeVehicule.\n",
    "* Ces changements expliquent une dégradation probable de la performance du modèle.\n",
    "* ces changements affectent directement les prédictions du modèle car il a été entraîné sur des distributions différentes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in Numerical_colomuns:\n",
    "          analyze_data_drift(data_train,data_drift,col)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analyse des KS Tests\n",
    "\n",
    "## 1. Résultats Clés\n",
    "\n",
    "### Statistique KS\n",
    "- **Mesure** : Distance maximale entre distributions cumulées.  \n",
    "- **Interprétation** : Plus elle est élevée, plus les distributions diffèrent.\n",
    "\n",
    "### p-value\n",
    "- **Résultat** : **0.0** pour toutes les variables, indiquant des différences **statistiquement significatives**.\n",
    "\n",
    "---\n",
    "\n",
    "## 2. Analyse par Variable\n",
    "\n",
    "- **`AgeConducteur`** : KS = **0.294** (Différence modérée).  \n",
    "  - Impact potentiel sur les performances.  \n",
    "\n",
    "- **`BonusMalus`** : KS = **0.453** (Différence élevée).  \n",
    "  - Dérive significative affectant les prédictions.  \n",
    "\n",
    "- **`AgeVehicule`** : KS = **0.530** (Différence critique).  \n",
    "  - Le modèle rencontre des cas non appris.  \n",
    "\n",
    "- **`PrimeCommerciale`** : KS = **0.277** (Différence modérée).  \n",
    "  - Liée directement à la cible, influence notable.  \n",
    "\n",
    "---\n",
    "\n",
    "## 3. Implications\n",
    "\n",
    "- Les dérives majeures dans **`AgeVehicule`** et **`BonusMalus`** expliquent la **dégradation des performances**.  \n",
    "- Le modèle est mal adapté aux distributions actuelles des données.\n",
    "\n",
    "---\n",
    "\n",
    "## 4. Recommandations\n",
    "\n",
    "### A. Réentraîner le Modèle\n",
    "- Collecter des données récentes et les intégrer dans l'entraînement.  \n",
    "\n",
    "### B. Surveillance Continue\n",
    "- Automatiser les KS Tests pour une détection proactive des dérives.  \n",
    "\n",
    "### C. Analyse Complémentaire\n",
    "- Identifier les causes des dérives :  \n",
    "  - Augmentation des véhicules récents (**`AgeVehicule`**).  \n",
    "  - Changements dans les politiques d'assurance (**`BonusMalus`**).  \n",
    "\n",
    "---\n",
    "\n",
    "## Conclusion\n",
    "\n",
    "Les KS Tests révèlent des **dérives significatives** dans plusieurs variables clés. Un **réentraînement** et une **surveillance continue** sont essentiels pour restaurer les performances du modèle.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in Numerical_colomuns:\n",
    "    jsd=calculate_jsd_categorical(data_train, data_drift, col)\n",
    "    print(f\"Jensen-Shannon Divergence for `{col}`: {jsd}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analyse de la Divergence de Jensen-Shannon (JS)\n",
    "\n",
    "La divergence JS évalue la similarité entre deux distributions. Elle varie de 0 (identiques) à 1 (complètement différentes). Voici les points clés concernant la dérive des données et son impact sur les performances.\n",
    "\n",
    "---\n",
    "\n",
    "## 1. Dérives Identifiées\n",
    "\n",
    "### Variables avec Dérive Majeure\n",
    "- **`BonusMalus`** : JS = **0.7349**  \n",
    "  → Changement dans les profils de risque.  \n",
    "- **`PrimeCommerciale`** : JS = **0.8326**  \n",
    "  → Nouvelle segmentation des primes.  \n",
    "\n",
    "### Variables avec Dérive Modérée\n",
    "- **`AgeVehicule`** : JS = **0.4998**  \n",
    "  → Modification des âges moyens des véhicules.  \n",
    "- **`AgeConducteur`** : JS = **0.2998**  \n",
    "  → Changements démographiques des conducteurs.  \n",
    "\n",
    "---\n",
    "\n",
    "## 2. Impact sur les Performances\n",
    "\n",
    "### Causes Principales\n",
    "- **`BonusMalus`** : Changements significatifs dans la structure des données.  \n",
    "- **`PrimeCommerciale`** : Évolution des tendances économiques.\n",
    "\n",
    "### Effets Observés\n",
    "- **Erreurs accrues** sur les prédictions des primes commerciales.  \n",
    "- Moindre performance pour :\n",
    "  - Les nouveaux profils de conducteurs.\n",
    "  - Les véhicules de segments non appris.\n",
    "\n",
    "---\n",
    "\n",
    "## 3. Recommandations\n",
    "\n",
    "### Variables Clés à Surveiller\n",
    "- **`BonusMalus`** : Ajuster le modèle aux nouvelles règles de risque.  \n",
    "- **`PrimeCommerciale`** : Réintégrer les nouvelles tendances économiques.  \n",
    "\n",
    "### Actions à Entreprendre\n",
    "- Réentraîner le modèle avec des données mises à jour.  \n",
    "- Automatiser la détection des dérives pour des corrections proactives.\n",
    "\n",
    "---\n",
    "\n",
    "## Conclusion\n",
    "\n",
    "Les divergences JS importantes pour **`BonusMalus`** et **`PrimeCommerciale`** confirment une dérive majeure. Pour maintenir la précision du modèle, un **réentraînement immédiat** est nécessaire.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Données pour le graphique\n",
    "variables = [\"AgeConducteur\", \"BonusMalus\", \"AgeVehicule\", \"PrimeCommerciale\"]\n",
    "divergences = [0.2998, 0.7349, 0.4998, 0.8326]\n",
    "\n",
    "# Création du barplot\n",
    "plt.figure(figsize=(8, 5))\n",
    "plt.bar(variables, divergences, color=['blue', 'red', 'orange', 'purple'], alpha=0.8)\n",
    "plt.axhline(y=0.5, color='r', linestyle='--', label=\"Seuil critique (0.5)\")\n",
    "plt.axhline(y=0.7, color='orange', linestyle='--', label=\"Seuil élevé (0.7)\")\n",
    "plt.title(\"Divergence de Jensen-Shannon des Variables Clés\")\n",
    "plt.ylabel(\"Divergence JS\")\n",
    "plt.xlabel(\"Variables\")\n",
    "plt.ylim(0, 1)\n",
    "plt.legend()\n",
    "plt.grid(axis=\"y\", linestyle=\"--\", alpha=0.7)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Les dérives significatives de BonusMalus et PrimeCommerciale indiquent un changement structurel dans les données récentes (changement dans les profils de risque et dans la segmentation des primes).\n",
    "* La dégradation des performances est fortement liée à ces variables.\n",
    "* Un réentraînement du modèle avec des données récentes, incluant ces nouvelles distributions, est nécessaire pour restaurer la précision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tracer_distributions_categoriques(pre_train, pre_data, Categorical_columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Les distributions sont globalement stables. **ClasseVehicle** montre une légère dérive qui pourrait avoir un impact modéré sur les performances.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in Categorical_columns:\n",
    "          analyze_data_drift(data_train,data_drift,col)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analyse des Tests Chi-Carré pour les Variables Catégoriques\n",
    "\n",
    "Les tests Chi-Carré évaluent les différences entre les distributions des variables catégoriques dans les données d'entraînement et les nouvelles données (drift).\n",
    "\n",
    "---\n",
    "\n",
    "## Résultats Clés\n",
    "\n",
    "- **p-value : 0.0** pour toutes les variables.  \n",
    "  - Les distributions diffèrent significativement, confirmant une **dérive importante** dans les dimensions catégoriques.\n",
    "\n",
    "---\n",
    "\n",
    "## Implications\n",
    "\n",
    "### Changements Observés\n",
    "- **Évolution démographique** :  \n",
    "  - Variations dans `SexeConducteur` et `Region`.\n",
    "- **Usage des véhicules** :  \n",
    "  - Modifications pour `UsageVehicule` et `ClasseVehicule`.\n",
    "- **Préférences techniques** :  \n",
    "  - Changements dans `CarburantVehicule` et `PuissanceVehicule`.\n",
    "\n",
    "---\n",
    "\n",
    "## Gestion de la Dérive\n",
    "\n",
    "### 1. Réentraînement\n",
    "- **Collecte de données récentes**.  \n",
    "- **Réentraînement du modèle** avec ces nouvelles données.\n",
    "\n",
    "### 2. Surveillance Continue\n",
    "- Automatiser les tests Chi-Carré pour détecter les dérives futures.\n",
    "\n",
    "---\n",
    "\n",
    "## Conclusion\n",
    "\n",
    "Les tests Chi-Carré confirment des **dérives significatives** dans les variables catégoriques. Ces évolutions doivent être adressées par un réentraînement et une surveillance proactive pour maintenir la performance du modèle.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in Categorical_columns:\n",
    "          jsd = calculate_jsd_categorical(data_train, data_drift, col)\n",
    "          print(f\"Jensen-Shannon Divergence for `{col}`: {jsd}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Priorité à **ClasseVehicule** pour investiguer l'impact de sa dérive.\n",
    "**FrequencePaiement** nécessite une analyse approfondie pour confirmer son influence.\n",
    "Les autres variables n'exigent pas d'action immédiate, leur stabilité réduit les risques de dérive conceptuelle."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Concept drift"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Analyse de la Dérive Conceptuelle : Changements dans l'Importance des Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Étape 1 : Entraîner un Random Forest sur les données anciennes\n",
    "rf_model_old = RandomForestRegressor(random_state=42)\n",
    "rf_model_old.fit(X_train, y_train)\n",
    "\n",
    "# Étape 2 : Importance des variables sur les données anciennes\n",
    "feature_importances_old = pd.Series(rf_model_old.feature_importances_, index=X_train.columns)\n",
    "\n",
    "# Étape 3 : Entraîner un Random Forest sur les nouvelles données\n",
    "rf_model_new = RandomForestRegressor(random_state=42)\n",
    "rf_model_new.fit(X, y)\n",
    "\n",
    "# Étape 4 : Importance des variables sur les nouvelles données\n",
    "feature_importances_new = pd.Series(rf_model_new.feature_importances_, index=X.columns)\n",
    "\n",
    "# Étape 5 : Comparer l'importance des variables\n",
    "importance_diff = feature_importances_new - feature_importances_old\n",
    "\n",
    "# Étape 6 : Visualisation des différences\n",
    "plt.figure(figsize=(20, 8))\n",
    "importance_diff.sort_values(ascending=False).plot(kind='bar', color='skyblue', alpha=0.8)\n",
    "plt.axhline(y=0, color='red', linestyle='--', label=\"Pas de changement\")\n",
    "plt.title(\"Différences d'Importance des Variables entre les Anciennes et Nouvelles Données\")\n",
    "plt.ylabel(\"Différence d'Importance\")\n",
    "plt.xlabel(\"Variables\")\n",
    "plt.xticks(rotation=45, ha='right')\n",
    "plt.legend()\n",
    "plt.grid(axis=\"y\", linestyle=\"--\", alpha=0.7)\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Description du Graphique\n",
    "\n",
    "Le graphique met en évidence les **différences absolues des coefficients** entre les modèles basés sur les anciennes et nouvelles données, classées par impact décroissant.\n",
    "\n",
    "---\n",
    "\n",
    "## Observations Clés\n",
    "\n",
    "### Variables Impactées\n",
    "- **`AgeVehicule_log`** :  \n",
    "  - Plus grande différence (> 1.2), indiquant un changement majeur dans son rôle.  \n",
    "\n",
    "- **`Driver_Vehicle_Age_Interaction`** :  \n",
    "  - Modification significative des interactions entre âge du conducteur et véhicule.  \n",
    "\n",
    "- **Classes de véhicules coûteux** :  \n",
    "  - Changements notables dans la segmentation des véhicules.  \n",
    "\n",
    "- **`AgeConducteur`** :  \n",
    "  - Variation modérée reflétant une évolution des profils de conducteurs.\n",
    "\n",
    "### Variables Stables\n",
    "- **`StatutMatrimonial_Single`**, **`Garage - Parking`** :  \n",
    "  - Peu de changements, faible impact.\n",
    "\n",
    "---\n",
    "\n",
    "## Impact et Actions\n",
    "\n",
    "- Les variables clés comme **`AgeVehicule_log`** montrent une **dérive conceptuelle**, réduisant la pertinence des prédictions.  \n",
    "- **Réentraînement** nécessaire avec des données récentes pour adapter le modèle.\n",
    "\n",
    "---\n",
    "\n",
    "## Conclusion\n",
    "\n",
    "Les variations importantes dans certaines variables clés confirment une **dérive conceptuelle**. Mettre à jour le modèle est crucial pour maintenir des performances fiables.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reg_old = LinearRegression()\n",
    "reg_old.fit(X_train, y_train)\n",
    "reg_new = LinearRegression()\n",
    "reg_new.fit(X, y)\n",
    "\n",
    "coeff_diff = pd.DataFrame({\n",
    "    \"Feature\": X_train.columns,\n",
    "    \"Old Coeff\": reg_old.coef_,\n",
    "    \"New Coeff\": reg_new.coef_,\n",
    "    \"Difference\": np.abs(reg_old.coef_ - reg_new.coef_)\n",
    "})\n",
    "\n",
    "plt.figure(figsize=(20, 8))\n",
    "coeff_diff.set_index(\"Feature\")[\"Difference\"].sort_values(ascending=False).plot(kind=\"bar\", color=\"skyblue\", alpha=0.8)\n",
    "plt.title(\"Différences des Coefficients entre les Anciennes et Nouvelles Données\")\n",
    "plt.ylabel(\"Différence Absolue des Coefficients\")\n",
    "plt.xlabel(\"Variables\")\n",
    "plt.xticks(rotation=45, ha=\"right\")\n",
    "plt.grid(axis=\"y\", linestyle=\"--\", alpha=0.7)\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## Description du Graphique\n",
    "\n",
    "Le graphique montre les **différences absolues des coefficients** entre les modèles entraînés sur les anciennes et les nouvelles données. Les variables sont classées par impact décroissant, mettant en évidence les changements significatifs.\n",
    "\n",
    "---\n",
    "\n",
    "## Observations Clés\n",
    "\n",
    "### Variables avec les Plus Grandes Différences\n",
    "- **`AgeVehicule_log`** :  \n",
    "  - Plus forte différence (> 1.2), indiquant un changement majeur dans son influence sur la cible.  \n",
    "  - Facteur clé de la dérive conceptuelle.  \n",
    "\n",
    "- **`Driver_Vehicle_Age_Interaction`** :  \n",
    "  - Modifications significatives dans l’interaction entre l’âge du conducteur et celui du véhicule.  \n",
    "\n",
    "- **Classes de véhicules coûteux (`ClasseVehicule_More expensive`, `Most expensive`)** :  \n",
    "  - Changements notables dans la segmentation des véhicules.  \n",
    "\n",
    "- **`AgeConducteur`** :  \n",
    "  - Variation modérée, indiquant des évolutions des profils de conducteurs.\n",
    "\n",
    "### Variables avec des Changements Modérés\n",
    "- Variables liées à la puissance des véhicules (ex. **`PuissanceVehicule_p4`**, **`p15`**) :  \n",
    "  - Changements dans la distribution ou l’importance de ces variables.\n",
    "\n",
    "### Variables Stables\n",
    "- Exemples : **`StatutMatrimonial_Single`**, **`Garage - Parking`** :  \n",
    "  - Peu de changement, impact négligeable sur la dérive.\n",
    "\n",
    "---\n",
    "\n",
    "## Impact sur les Performances\n",
    "\n",
    "- Variables critiques, comme **`AgeVehicule_log`** et **`Driver_Vehicle_Age_Interaction`**, ont subi des modifications importantes, causant une **dérive conceptuelle**.  \n",
    "- Les relations modifiées dans les segments de véhicules et les interactions influencent directement les prédictions.\n",
    "\n",
    "---\n",
    "\n",
    "## Conclusion\n",
    "\n",
    "- Les **changements significatifs** dans les coefficients de certaines variables clés signalent une **dérive conceptuelle**.  \n",
    "- Un **réentraînement** du modèle est indispensable pour rétablir ses performances.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mse_correlation = comparer_matrices_correlation(data_train, data_drift, Numerical_colomuns)\n",
    "print(f\"Erreur Quadratique Moyenne entre les matrices : {mse_correlation}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Résumé des Visualisations\n",
    "\n",
    "Les heatmaps révèlent :  \n",
    "1. **Corrélation des données d'entraînement** : Relations initiales.  \n",
    "2. **Corrélation des nouvelles données** : Changements détectés.  \n",
    "3. **Différences** : Impact des variations.  \n",
    "\n",
    "---\n",
    "\n",
    "## Observations Clés\n",
    "\n",
    "### Données d'Entraînement\n",
    "- **Relation forte (-0.51)** entre `AgeConducteur` et `BonusMalus`.  \n",
    "- Corrélation faible entre `AgeVehicule` et `PrimeCommerciale` (-0.06).\n",
    "\n",
    "### Nouvelles Données\n",
    "- **Inversion (+0.43)** entre `AgeConducteur` et `BonusMalus`.  \n",
    "- Faible impact sur `AgeVehicule` et `PrimeCommerciale` (-0.15).\n",
    "\n",
    "### Différences\n",
    "- Augmentation de **+0.94** dans `AgeConducteur` et `BonusMalus`.  \n",
    "- Réduction de **-0.31** entre `AgeConducteur` et `AgeVehicule`.\n",
    "\n",
    "---\n",
    "\n",
    "## Impact sur le Modèle\n",
    "\n",
    "- Changements critiques dans `AgeConducteur` et `BonusMalus` → **dérive conceptuelle**.  \n",
    "- Relations stables (ex. `PrimeCommerciale`) peu contributives à la dérive.\n",
    "\n",
    "---\n",
    "\n",
    "## Recommandations\n",
    "\n",
    "1. **Réentraînement du Modèle** :  \n",
    "   Intégrer les nouvelles relations dans le dataset pour aligner le modèle.  \n",
    "   \n",
    "2. **Surveillance Continue** :  \n",
    "   Automatiser la détection de dérives sur les relations clés.\n",
    "\n",
    "---\n",
    "\n",
    "\n",
    "- Les relations clés, notamment entre `AgeConducteur` et `BonusMalus`, ont évolué significativement.  \n",
    "- Un réentraînement et une surveillance proactive sont essentiels pour rétablir les performances et éviter les biais dans les prédictions.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Conclusion Générale"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Les analyses mettent en évidence des **dérives significatives** entre les données d'entraînement et les nouvelles données (drift), affectant la performance du modèle.\n",
    "\n",
    "---\n",
    "\n",
    "### Résumé des Problèmes Clés\n",
    "1. **Dérive Conceptuelle et Distributionnelle :**\n",
    "   - **`BonusMalus`** et **`PrimeCommerciale`** montrent des divergences importantes (Jensen-Shannon et KS Tests).  \n",
    "   - Les relations clés entre variables ont changé, notamment entre `AgeConducteur` et `BonusMalus` (inversion de la corrélation).  \n",
    "\n",
    "2. **Impact sur les Résidus :**\n",
    "   - Les résidus drift présentent des biais systémiques, une variance accrue et un comportement non normal.  \n",
    "   - Les prédictions sur le drift sont moins fiables, avec une perte de généralisation.\n",
    "\n",
    "3. **Différences dans les Coefficients :**\n",
    "   - Des changements majeurs dans des variables critiques comme `AgeVehicule_log` et `Driver_Vehicle_Age_Interaction` affectent l'interprétation du modèle.\n",
    "\n",
    "4. **Tests Statistiques :**\n",
    "   - Les p-values (Chi-Carré, KS) confirment des dérives statistiquement significatives dans les distributions catégoriques et continues.\n",
    "\n",
    "---\n",
    "\n",
    "### Conséquences\n",
    "- Les dérives identifiées entraînent une **dégradation des performances** :  \n",
    "  - Augmentation des erreurs de prédiction.  \n",
    "  - Réduction de la robustesse face aux nouvelles observations.  \n",
    "\n",
    "- Les données d'entraînement sont **obsolètes** et ne reflètent plus les dynamiques actuelles.\n",
    "\n",
    "---\n",
    "\n",
    "### Recommandations\n",
    "1. **Réentraîner le Modèle :**\n",
    "   - Intégrer des données récentes pour refléter les nouvelles distributions et relations.\n",
    "   - Inclure les variables critiques comme `BonusMalus` et `AgeVehicule`.\n",
    "\n",
    "2. **Surveillance Continue :**\n",
    "   - Automatiser les tests (KS, Chi-Carré, divergence JS) pour détecter et corriger les dérives futures.\n",
    "\n",
    "3. **Analyse Complémentaire :**\n",
    "   - Identifier les causes des dérives :\n",
    "     - Changements démographiques (`AgeConducteur`, `Region`).\n",
    "     - Évolutions économiques et comportementales (`PrimeCommerciale`, `UsageVehicule`).\n",
    "\n",
    "---\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
